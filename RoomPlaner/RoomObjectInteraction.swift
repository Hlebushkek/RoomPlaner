//
//  RoomObjectInteraction.swift
//  RoomPlaner
//
//  Created by Hlib Sobolevskyi on 19.01.2023.
//

import UIKit
import ARKit

class VirtualObjectInteraction: NSObject, UIGestureRecognizerDelegate {
    
    let translateAssumingInfinitePlane = true
    
    let sceneView: RoomReviewingARView
    
    let viewController: RoomReviewingViewController
    
    var selectedObject: RoomVirtualObject?
    
    var trackedObject: RoomVirtualObject? {
        didSet {
            guard trackedObject != nil else { return }
            selectedObject = trackedObject
        }
    }
    
    private var currentTrackingPosition: CGPoint?
    
    init(sceneView: RoomReviewingARView, viewController: RoomReviewingViewController) {
        self.sceneView = sceneView
        self.viewController = viewController
        super.init()
        
        createPanGestureRecognizer(sceneView)
        
        let rotationGesture = UIRotationGestureRecognizer(target: self, action: #selector(didRotate(_:)))
        rotationGesture.delegate = self
        sceneView.addGestureRecognizer(rotationGesture)

        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(didTap(_:)))
        sceneView.addGestureRecognizer(tapGesture)
    }
    
    func createPanGestureRecognizer(_ sceneView: RoomReviewingARView) {
//        let panGesture = ThresholdPanGesture(target: self, action: #selector(didPan(_:)))
//        panGesture.delegate = self
//        sceneView.addGestureRecognizer(panGesture)
    }
    
    // MARK: - Gesture Actions
    
//    @objc
//    func didPan(_ gesture: ThresholdPanGesture) {
//        switch gesture.state {
//        case .began:
//            // Check for an object at the touch location.
//            if let object = objectInteracting(with: gesture, in: sceneView) {
//                trackedObject = object
//            }
//
//        case .changed where gesture.isThresholdExceeded:
//            guard let object = trackedObject else { return }
//            // Move an object if the displacment threshold has been met.
//            translate(object, basedOn: updatedTrackingPosition(for: object, from: gesture))
//
//            gesture.setTranslation(.zero, in: sceneView)
//
//        case .changed:
//            // Ignore the pan gesture until the displacment threshold is exceeded.
//            break
//
//        case .ended:
//            // Update the object's position when the user stops panning.
//            guard let object = trackedObject else { break }
//            setDown(object, basedOn: updatedTrackingPosition(for: object, from: gesture))
//
//            fallthrough
//
//        default:
//            // Reset the current position tracking.
//            currentTrackingPosition = nil
//            trackedObject = nil
//        }
//    }
    
    func updatedTrackingPosition(for object: RoomVirtualObject, from gesture: UIPanGestureRecognizer) -> CGPoint {
        let translation = gesture.translation(in: sceneView)
        
        let currentPosition = currentTrackingPosition ?? CGPoint(sceneView.projectPoint(object.position))
        let updatedPosition = CGPoint(x: currentPosition.x + translation.x, y: currentPosition.y + translation.y)
        currentTrackingPosition = updatedPosition
        return updatedPosition
    }

    /**
     For looking down on the object (99% of all use cases), you subtract the angle.
     To make rotation also work correctly when looking from below the object one would have to
     flip the sign of the angle depending on whether the object is above or below the camera.
     - Tag: didRotate */
    @objc
    func didRotate(_ gesture: UIRotationGestureRecognizer) {
        guard gesture.state == .changed else { return }
        
        trackedObject?.objectRotation -= Float(gesture.rotation)
        
        gesture.rotation = 0
    }
    
    /// Handles the interaction when the user taps the screen.
    @objc
    func didTap(_ gesture: UITapGestureRecognizer) {
        let touchLocation = gesture.location(in: sceneView)
        
        if let tappedObject = sceneView.virtualObject(at: touchLocation) {
            
            // If an object exists at the tap location, select it.
            selectedObject = tappedObject
        } else if let object = selectedObject {
            
            // Otherwise, move the selected object to its new position at the tap location.
            setDown(object, basedOn: touchLocation)
        }
    }
    
    func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldRecognizeSimultaneouslyWith otherGestureRecognizer: UIGestureRecognizer) -> Bool {
        // Allow objects to be translated and rotated at the same time.
        return true
    }

    /** A helper method to return the first object that is found under the provided `gesture`s touch locations.
     Performs hit tests using the touch locations provided by gesture recognizers. By hit testing against the bounding
     boxes of the virtual objects, this function makes it more likely that a user touch will affect the object even if the
     touch location isn't on a point where the object has visible content. By performing multiple hit tests for multitouch
     gestures, the method makes it more likely that the user touch affects the intended object.
      - Tag: TouchTesting
    */
    private func objectInteracting(with gesture: UIGestureRecognizer, in view: ARSCNView) -> RoomVirtualObject? {
        for index in 0..<gesture.numberOfTouches {
            let touchLocation = gesture.location(ofTouch: index, in: view)
            
            // Look for an object directly under the `touchLocation`.
            if let object = sceneView.virtualObject(at: touchLocation) {
                return object
            }
        }
        
        // As a last resort look for an object under the center of the touches.
        if let center = gesture.center(in: view) {
            return sceneView.virtualObject(at: center)
        }
        
        return nil
    }
    
    // MARK: - Update object position
    /// - Tag: DragVirtualObject
    func translate(_ object: RoomVirtualObject, basedOn screenPos: CGPoint) {
        object.stopTrackedRaycast()
        
        // Update the object by using a one-time position request.
        if let query = sceneView.raycastQuery(from: screenPos, allowing: .estimatedPlane, alignment: object.allowedAlignment) {
            viewController.createRaycastAndUpdate3DPosition(of: object, from: query)
        }
    }
    
    func setDown(_ object: RoomVirtualObject, basedOn screenPos: CGPoint) {
        object.stopTrackedRaycast()
        
        // Prepare to update the object's anchor to the current location.
        object.shouldUpdateAnchor = true
        
        // Attempt to create a new tracked raycast from the current location.
        if let query = sceneView.raycastQuery(from: screenPos, allowing: .estimatedPlane, alignment: object.allowedAlignment),
            let raycast = viewController.createTrackedRaycastAndSet3DPosition(of: object, from: query) {
            object.raycast = raycast
        } else {
            // If the tracked raycast did not succeed, simply update the anchor to the object's current position.
            object.shouldUpdateAnchor = false
            viewController.updateQueue.async {
                self.sceneView.addOrUpdateAnchor(for: object)
            }
        }
    }
}

/// Extends `UIGestureRecognizer` to provide the center point resulting from multiple touches.
extension UIGestureRecognizer {
    func center(in view: UIView) -> CGPoint? {
        guard numberOfTouches > 0 else { return nil }
        
        let first = CGRect(origin: location(ofTouch: 0, in: view), size: .zero)

        let touchBounds = (1..<numberOfTouches).reduce(first) { touchBounds, index in
            return touchBounds.union(CGRect(origin: location(ofTouch: index, in: view), size: .zero))
        }

        return CGPoint(x: touchBounds.midX, y: touchBounds.midY)
    }
}

